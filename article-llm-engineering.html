<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="llm engineering">
    <title>LLM 应用工程化的几点思考 | 郑梓辉</title>
        <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <link rel="stylesheet" href="css/common.css">
    <link rel="stylesheet" href="css/article-common.css">
</head>
<body class="article-page">
    <canvas id="particles-canvas"></canvas>

    <nav>
        <div class="container">
            <div class="logo"><i class="fas fa-code"></i> blog</div>
            <ul class="nav-links">
                <li><a href="index.html#home">首页</a></li>
                <li><a href="index.html#projects">项目</a></li>
                <li><a href="blog.html">博客</a></li>
                <li><a href="index.html#about">关于</a></li>
                <li><a href="index.html#contact">联系</a></li>
            </ul>
            <div class="hamburger" aria-label="菜单" role="button" tabindex="0">
                <span></span><span></span><span></span>
            </div>
        </div>
    </nav>

    <section class="article-hero">
        <div class="container">
            <a href="blog.html" class="back-link"><i class="fas fa-arrow-left"></i> 返回博客</a>
            <span class="article-tag tag-orange">AI工程</span>
            <h1 class="article-title">LLM 应用工程化的几点思考</h1>
            <div class="article-meta">
                <span><i class="far fa-calendar"></i> 2025-09-20</span>
                <span><i class="fas fa-user"></i> 郑梓辉</span>
            </div>
        </div>
    </section>

    <article class="container">
        <div class="article-content">
            <h2>引言</h2>
            <p>
                随着大语言模型（LLM）的快速发展，越来越多的开发者开始将 LLM 集成到生产应用中。
                然而，从概念验证（PoC）到生产级应用（Production-ready）的过程并不平坦。
                本文分享一些在 LLM 应用工程化过程中的思考和实践。
            </p>

            <h2>一、模型选择与成本权衡</h2>

            <h3>核心问题</h3>
            <p>
                选择合适的模型是第一步，需要在以下几个维度进行权衡：
            </p>

            <ul>
                <li><strong>能力</strong>：模型的理解和生成能力是否满足任务需求</li>
                <li><strong>成本</strong>：API 调用费用、部署成本、维护成本</li>
                <li><strong>延迟</strong>：响应时间是否满足业务需求</li>
                <li><strong>隐私</strong>：数据是否需要本地处理</li>
            </ul>

            <pre><code>// 模型选择决策树示例
function selectModel(task) {
    const requirements = analyzeTask(task);
    
    if (requirements.latency &lt; 100ms) {
        return useLocalSmallModel();
    } else if (requirements.needsAccuracy) {
        return useAPI(GPT4);
    } else {
        return useAPI(GPT35Turbo);
    }
}</code></pre>

            <h2>二、提示词工程的系统化方法</h2>

            <h3>从艺术到科学</h3>
            <p>
                早期的提示词设计往往凭经验，现在我们需要更系统的方法：
            </p>

            <ul>
                <li><strong>模板化设计</strong>：建立可复用的提示词模板库</li>
                <li><strong>版本控制</strong>：对提示词的各个版本进行跟踪和评估</li>
                <li><strong>A/B 测试</strong>：量化评估不同提示词的效果</li>
                <li><strong>自动优化</strong>：利用反馈数据进行提示词优化</li>
            </ul>

            <h3>关键技巧</h3>
            <ol>
                <li><strong>角色设定</strong>：明确定义 AI 的角色和背景</li>
                <li><strong>少样本学习</strong>：提供示例来引导输出格式</li>
                <li><strong>链式思考</strong>：让模型逐步推理而不是直接给答案</li>
                <li><strong>温度控制</strong>：调整 temperature 参数控制输出多样性</li>
            </ol>

            <h2>三、可靠性与容错设计</h2>

            <h3>生产环境的挑战</h3>
            <p>
                LLM 模型的不确定性使得容错设计变得尤为重要：
            </p>

            <ul>
                <li>响应失败或超时处理</li>
                <li>输出格式验证和纠正</li>
                <li>降级策略（回退到规则系统或缓存结果）</li>
                <li>幻觉（Hallucination）检测和缓解</li>
            </ul>

            <pre><code>// 实现重试和降级策略
async function robustLLMCall(prompt, retries = 3) {
    for (let i = 0; i &lt; retries; i++) {
        try {
            const response = await callLLM(prompt);
            if (validateResponse(response)) {
                return response;
            }
        } catch (error) {
            if (i === retries - 1) {
                return fallbackStrategy(prompt);
            }
        }
    }
}</code></pre>

            <h2>四、评估与监控</h2>

            <h3>定量评估</h3>
            <p>
                不同于传统软件，LLM 应用的评估需要自定义指标：
            </p>

            <ul>
                <li><strong>自动化指标</strong>：BLEU、ROUGE、F1 分数等（受限）</li>
                <li><strong>人工评估</strong>：建立评分标准和评估流程</li>
                <li><strong>用户反馈</strong>：点赞/点踩、显式评分等</li>
                <li><strong>业务指标</strong>：转化率、完成度、满意度等</li>
            </ul>

            <h3>持续监控</h3>
            <p>
                线上监控应该涵盖：
            </p>
            <ul>
                <li>API 调用延迟和成本</li>
                <li>模型输出质量的漂移（drift）</li>
                <li>用户反馈的变化趋势</li>
                <li>异常和边界情况的出现频率</li>
            </ul>

            <h2>五、伦理和安全考量</h2>

            <p>
                在应用 LLM 时，需要考虑：
            </p>

            <ul>
                <li><strong>偏见</strong>：模型可能存在的社会偏见和刻板印象</li>
                <li><strong>安全</strong>：防止恶意注入和对抗性输入</li>
                <li><strong>透明度</strong>：向用户清楚地说明使用了 AI</li>
                <li><strong>数据隐私</strong>：确保用户数据的安全和隐私</li>
            </ul>

            <h2>总结</h2>
            <p>
                LLM 工程化是一个涉及多个方面的综合工程。成功的关键在于：
            </p>
            <ol>
                <li>明确的业务目标和评估标准</li>
                <li>系统化和科学化的方法论</li>
                <li>持续的监控、反馈和迭代</li>
                <li>对安全和伦理的重视</li>
            </ol>

            <p>
                这个领域还在快速演进，新的最佳实践不断涌现。
                保持学习和开放心态，是在这个领域长期成功的必要条件。
            </p>
        </div>
    </article>

    <footer class="site-footer">
        <div class="container">
            <p><i class="fas fa-code"></i> 用工程化手段让 AI 落地</p>
            <p>&copy; 2025 Zihui Zheng. Built with passion.</p>
        </div>
    </footer>

    <script src="js/common.js"></script>
</body>
</html>